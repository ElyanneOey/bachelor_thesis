{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: larq in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (0.13.0)\n",
      "Requirement already satisfied: packaging>=19.2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from larq) (23.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.15.4 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from larq) (1.16.4)\n",
      "Requirement already satisfied: importlib-metadata<4.0,>=2.0; python_version < \"3.8\" in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from larq) (3.10.1)\n",
      "Requirement already satisfied: terminaltables>=3.1.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from larq) (3.1.10)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from importlib-metadata<4.0,>=2.0; python_version < \"3.8\"->larq) (0.5.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from importlib-metadata<4.0,>=2.0; python_version < \"3.8\"->larq) (4.0.1)\n",
      "Requirement already satisfied: keras-tuner in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (1.3.5)\n",
      "Requirement already satisfied: kt-legacy in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from keras-tuner) (1.0.5)\n",
      "Requirement already satisfied: requests in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from keras-tuner) (2.22.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from keras-tuner) (23.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (2022.12.7)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (1.24.2)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (2.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install larq\n",
    "!pip install keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.7.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "import larq as lq\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toy-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images_left_under = 50000\n",
    "num_images_right_above = 50000\n",
    "\n",
    "dataset_left_under = np.empty((num_images_left_under, 2, 2), dtype=np.uint8)\n",
    "dataset_right_above = np.empty((num_images_right_above, 2, 2), dtype=np.uint8)\n",
    "\n",
    "for i in range(num_images_left_under):\n",
    "    image = np.zeros((2, 2), dtype=np.uint8)\n",
    "    image[0, 0] = np.random.randint(0, 255) #255 not included\n",
    "    image[0, 1] = np.random.randint(0, 255)\n",
    "    image[1, 1] = np.random.randint(0, 255)\n",
    "    image[1, 0] = 255\n",
    "    dataset_left_under[i] = image\n",
    "    \n",
    "for i in range(num_images_right_above):\n",
    "    image = np.zeros((2, 2), dtype=np.uint8)\n",
    "    image[0, 0] = np.random.randint(0, 255)\n",
    "    image[1, 0] = np.random.randint(0, 255)\n",
    "    image[1, 1] = np.random.randint(0, 255)\n",
    "    image[0, 1] = 255\n",
    "    dataset_right_above[i] = image    \n",
    "\n",
    "y_left_under = np.full(num_images_left_under, 1)\n",
    "y_right_above = np.full(num_images_right_above, 0) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure\n",
    "plt.imshow(dataset_left_under[10], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dataset = np.concatenate((dataset_left_under, dataset_right_above))\n",
    "y_dataset = np.concatenate((y_left_under, y_right_above))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x_dataset, y_dataset, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = x_train.reshape(80000, 4).astype(\"float32\") / 255.0, x_test.reshape(20000, 4).astype(\"float32\") / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = tf.keras.utils.to_categorical(y_test, 2)\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST dataset resize to 2x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist # Dataset consistent of 28x28 images of the handwritten numbers 0 to 9\n",
    "\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data() \n",
    "\n",
    "print(x_train.shape) \n",
    "#print(x_train)\n",
    "train_0_1 = np.where((y_train == 0 ) | (y_train == 1))\n",
    "test_0_1 = np.where((y_test == 0) | (y_test == 1))\n",
    "x_train, y_train = x_train[train_0_1], y_train[train_0_1]\n",
    "x_test, y_test = x_test[test_0_1], y_test[test_0_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resize\n",
    "x_train = np.expand_dims(x_train, axis=-1) #extra dimension for resizing\n",
    "x_train = tf.image.resize(x_train, [2,2]) \n",
    "x_test = np.expand_dims(x_test, axis=-1)\n",
    "x_test = tf.image.resize(x_test, [2,2]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove extra dimension\n",
    "x_train = x_train[:, :, :, 0] \n",
    "x_test = x_test[:, :, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow to numpy array\n",
    "x_train = x_train.numpy()\n",
    "x_test = x_test.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before preproccessing, the data (intensity of the pixels) ranges from 0 (which corresponds to black) \n",
    "# to 255 (which corresponds to white). Any intensity in between can be considered as gray\n",
    "# The data should be in a scale from 0 to 1, so I divided the intensity of the pixels by 255\n",
    "x_train, x_test = x_train.reshape(12665, 4).astype(\"float32\") / 255.0, x_test.reshape(2115, 4).astype(\"float32\") / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = tf.keras.utils.to_categorical(y_test, 2)\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    input_dim = 4\n",
    "    classes = 2\n",
    "\n",
    "    # This is the main network we'll actually use to predict labels.\n",
    "    model = keras.Sequential(\n",
    "        [keras.layers.Dense(6, activation=tf.nn.sigmoid, use_bias=False),\n",
    "         keras.layers.Dense(2, activation=tf.nn.softmax, use_bias=False),]\n",
    "    )\n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='categorical_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 4\n",
    "classes = 2\n",
    "\n",
    "# This is the main network we'll actually use to predict labels.\n",
    "model = keras.Sequential(\n",
    "    [keras.layers.Dense(2, activation=tf.nn.softmax),]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "169/169 [==============================] - 0s 937us/step - loss: 2.2177 - accuracy: 0.2459\n",
      "Epoch 2/50\n",
      "169/169 [==============================] - 0s 973us/step - loss: 2.1846 - accuracy: 0.2503\n",
      "Epoch 3/50\n",
      "169/169 [==============================] - 0s 981us/step - loss: 2.1529 - accuracy: 0.2542\n",
      "Epoch 4/50\n",
      "169/169 [==============================] - 0s 991us/step - loss: 2.1221 - accuracy: 0.2564\n",
      "Epoch 5/50\n",
      "169/169 [==============================] - 0s 1ms/step - loss: 2.0923 - accuracy: 0.2597\n",
      "Epoch 6/50\n",
      "169/169 [==============================] - 0s 895us/step - loss: 2.0634 - accuracy: 0.2624\n",
      "Epoch 7/50\n",
      "169/169 [==============================] - 0s 886us/step - loss: 2.0354 - accuracy: 0.2651\n",
      "Epoch 8/50\n",
      "169/169 [==============================] - 0s 884us/step - loss: 2.0082 - accuracy: 0.2684\n",
      "Epoch 9/50\n",
      "169/169 [==============================] - 0s 884us/step - loss: 1.9818 - accuracy: 0.2700\n",
      "Epoch 10/50\n",
      "169/169 [==============================] - 0s 872us/step - loss: 1.9561 - accuracy: 0.2717\n",
      "Epoch 11/50\n",
      "169/169 [==============================] - 0s 884us/step - loss: 1.9310 - accuracy: 0.2731\n",
      "Epoch 12/50\n",
      "169/169 [==============================] - 0s 1ms/step - loss: 1.9066 - accuracy: 0.2755\n",
      "Epoch 13/50\n",
      "169/169 [==============================] - 0s 960us/step - loss: 1.8827 - accuracy: 0.5261\n",
      "Epoch 14/50\n",
      "169/169 [==============================] - 0s 934us/step - loss: 1.8594 - accuracy: 0.6593\n",
      "Epoch 15/50\n",
      "169/169 [==============================] - 0s 931us/step - loss: 1.8366 - accuracy: 0.6607\n",
      "Epoch 16/50\n",
      "169/169 [==============================] - 0s 954us/step - loss: 1.8143 - accuracy: 0.6625\n",
      "Epoch 17/50\n",
      "169/169 [==============================] - 0s 933us/step - loss: 1.7924 - accuracy: 0.6641\n",
      "Epoch 18/50\n",
      "169/169 [==============================] - 0s 922us/step - loss: 1.7710 - accuracy: 0.6653\n",
      "Epoch 19/50\n",
      "169/169 [==============================] - 0s 970us/step - loss: 1.7500 - accuracy: 0.6667\n",
      "Epoch 20/50\n",
      "169/169 [==============================] - 0s 889us/step - loss: 1.7293 - accuracy: 0.6686\n",
      "Epoch 21/50\n",
      "169/169 [==============================] - 0s 935us/step - loss: 1.7090 - accuracy: 0.6698\n",
      "Epoch 22/50\n",
      "169/169 [==============================] - 0s 898us/step - loss: 1.6891 - accuracy: 0.6716\n",
      "Epoch 23/50\n",
      "169/169 [==============================] - 0s 909us/step - loss: 1.6695 - accuracy: 0.6739\n",
      "Epoch 24/50\n",
      "169/169 [==============================] - 0s 893us/step - loss: 1.6503 - accuracy: 0.6750\n",
      "Epoch 25/50\n",
      "169/169 [==============================] - 0s 876us/step - loss: 1.6313 - accuracy: 0.6759\n",
      "Epoch 26/50\n",
      "169/169 [==============================] - 0s 987us/step - loss: 1.6126 - accuracy: 0.6771\n",
      "Epoch 27/50\n",
      "169/169 [==============================] - 0s 958us/step - loss: 1.5942 - accuracy: 0.6783\n",
      "Epoch 28/50\n",
      "169/169 [==============================] - 0s 933us/step - loss: 1.5761 - accuracy: 0.6794\n",
      "Epoch 29/50\n",
      "169/169 [==============================] - 0s 961us/step - loss: 1.5583 - accuracy: 0.6813\n",
      "Epoch 30/50\n",
      "169/169 [==============================] - 0s 960us/step - loss: 1.5407 - accuracy: 0.6824\n",
      "Epoch 31/50\n",
      "169/169 [==============================] - 0s 896us/step - loss: 1.5234 - accuracy: 0.6841\n",
      "Epoch 32/50\n",
      "169/169 [==============================] - 0s 897us/step - loss: 1.5063 - accuracy: 0.6860\n",
      "Epoch 33/50\n",
      "169/169 [==============================] - 0s 1ms/step - loss: 1.4895 - accuracy: 0.6876\n",
      "Epoch 34/50\n",
      "169/169 [==============================] - 0s 1ms/step - loss: 1.4729 - accuracy: 0.6891\n",
      "Epoch 35/50\n",
      "169/169 [==============================] - 0s 1ms/step - loss: 1.4565 - accuracy: 0.6904\n",
      "Epoch 36/50\n",
      "169/169 [==============================] - 0s 861us/step - loss: 1.4404 - accuracy: 0.6913\n",
      "Epoch 37/50\n",
      "169/169 [==============================] - 0s 894us/step - loss: 1.4245 - accuracy: 0.6924\n",
      "Epoch 38/50\n",
      "169/169 [==============================] - 0s 895us/step - loss: 1.4087 - accuracy: 0.6936\n",
      "Epoch 39/50\n",
      "169/169 [==============================] - 0s 974us/step - loss: 1.3932 - accuracy: 0.6946\n",
      "Epoch 40/50\n",
      "169/169 [==============================] - 0s 952us/step - loss: 1.3778 - accuracy: 0.6961\n",
      "Epoch 41/50\n",
      "169/169 [==============================] - 0s 959us/step - loss: 1.3627 - accuracy: 0.6978\n",
      "Epoch 42/50\n",
      "169/169 [==============================] - 0s 943us/step - loss: 1.3477 - accuracy: 0.6988\n",
      "Epoch 43/50\n",
      "169/169 [==============================] - 0s 967us/step - loss: 1.3329 - accuracy: 0.7005\n",
      "Epoch 44/50\n",
      "169/169 [==============================] - 0s 911us/step - loss: 1.3183 - accuracy: 0.7018\n",
      "Epoch 45/50\n",
      "169/169 [==============================] - 0s 924us/step - loss: 1.3039 - accuracy: 0.7030\n",
      "Epoch 46/50\n",
      "169/169 [==============================] - 0s 1ms/step - loss: 1.2896 - accuracy: 0.7040\n",
      "Epoch 47/50\n",
      "169/169 [==============================] - 0s 960us/step - loss: 1.2754 - accuracy: 0.7056\n",
      "Epoch 48/50\n",
      "169/169 [==============================] - 0s 953us/step - loss: 1.2615 - accuracy: 0.7063\n",
      "Epoch 49/50\n",
      "169/169 [==============================] - 0s 882us/step - loss: 1.2477 - accuracy: 0.7075\n",
      "Epoch 50/50\n",
      "169/169 [==============================] - 0s 891us/step - loss: 1.2340 - accuracy: 0.7083\n",
      "67/67 [==============================] - 0s 756us/step - loss: 1.2091 - accuracy: 0.7031\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='categorical_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "# When the next line is executed, the training of the model is done.\n",
    "# Epochs stands for the number of cycles the ANN trains for, with the entire training dataset. \n",
    "history = model.fit(x_train, y_train, epochs=50, batch_size=75)\n",
    "    \n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 0s 830us/step - loss: 0.5126 - accuracy: 0.7901\n",
      "67/67 [==============================] - 0s 813us/step - loss: 0.5148 - accuracy: 0.8128\n",
      "67/67 [==============================] - 0s 824us/step - loss: 0.5390 - accuracy: 0.8043\n",
      "67/67 [==============================] - 0s 815us/step - loss: 0.4875 - accuracy: 0.8123\n",
      "67/67 [==============================] - 0s 864us/step - loss: 0.5096 - accuracy: 0.8005\n",
      "67/67 [==============================] - 0s 822us/step - loss: 0.5273 - accuracy: 0.8009\n",
      "67/67 [==============================] - 0s 825us/step - loss: 0.4963 - accuracy: 0.8028\n",
      "67/67 [==============================] - 0s 804us/step - loss: 0.4870 - accuracy: 0.8095\n",
      "67/67 [==============================] - 0s 801us/step - loss: 0.4836 - accuracy: 0.8052\n",
      "67/67 [==============================] - 0s 802us/step - loss: 0.5509 - accuracy: 0.7877\n"
     ]
    }
   ],
   "source": [
    "accu = []\n",
    "\n",
    "for i in range(10):\n",
    "    #model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='categorical_crossentropy',\n",
    "    #             metrics=['accuracy'])\n",
    "    model = create_model()\n",
    "    # When the next line is executed, the training of the model is done.\n",
    "    # Epochs stands for the number of cycles the ANN trains for, with the entire training dataset. \n",
    "    history = model.fit(x_train, y_train, epochs=50, batch_size=75, verbose=0)\n",
    "    \n",
    "    test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "    accu.append(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 0s 775us/step - loss: 0.3799 - accuracy: 0.8463\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.8026004791259765\n",
      "Standard Deviation: 0.007999492405818973\n"
     ]
    }
   ],
   "source": [
    "data = [0.8444, 0.8444, 0.8463]  # Replace with your data\n",
    "\n",
    "mean = np.mean(accu)\n",
    "std = np.std(accu)\n",
    "\n",
    "print(\"Mean:\", mean)\n",
    "print(\"Standard Deviation:\", std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
